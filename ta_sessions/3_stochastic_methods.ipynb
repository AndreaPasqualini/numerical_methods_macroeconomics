{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VFI, Stochastic Problems and the Meaning of All of This"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last session, we took a look at deterministic problems.\n",
    "Here, we look at stochastic problems.\n",
    "\n",
    "We take the Neoclassical Growth Model with stochastic capital productivity as an example.\n",
    "The problem is the following:\n",
    "\n",
    "\\begin{align*}\n",
    "    V(k, a) &= \\max_{c, k'} \\dfrac{c^{1-\\gamma}}{1-\\gamma} + \\beta \\cdot \\mathbf{E} \\left( V \\left( k', a' \\right) \\right) \\\\\n",
    "            &\\qquad \\text{s.t.}\n",
    "                \\begin{cases}\n",
    "                    c + k' \\leq \\exp(a) \\cdot k^\\alpha + (1-\\delta) k \\\\\n",
    "                    a' = (1-\\rho) \\mu + \\rho a + \\varepsilon' \\\\\n",
    "                    \\varepsilon' \\overset{iid}{\\sim} \\mathcal{N} (0, \\sigma^2)\\\\\n",
    "                    c \\geq 0\n",
    "                \\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerical complication with this model is that $a$ takes on a continuum of values.\n",
    "When we use VFI, we need to discretize the grid for the state space, which in this case is $(k, a)$.\n",
    "While discretizing the grid for capital is relatively straightforward, discretizing a stochastic (exogenous) variable is less obvious.\n",
    "Obtaining values on the grid for $a$ is not the problem.\n",
    "The problem is discretizing the randomness associated to it.\n",
    "\n",
    "This session is organized in three parts.\n",
    "First, we look at how we can discretize AR(1) processes, which are ubiquitous in Macro models.\n",
    "Second, we use VFI to solve the problem above.\n",
    "Finally, we get to see what we can use numerical solutions for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "from scipy import stats as st\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretizing AR(1) processes\n",
    "\n",
    "The theory of how to do that is discussed in class with the Professor.\n",
    "Here we quickly review the methods and we look at some code that implements them.\n",
    "The methods we look at are three:\n",
    "- [Tauchen (1986)](https://doi.org/10.1016/0165-1765(86)90168-0)\n",
    "- [Tauchen and Hussey (1991)](https://doi.org/10.2307/2938261)\n",
    "- Rouwenhorst, revamped by [Kopecky and Suen (2010)](https://doi.org/10.1016/j.red.2010.02.002)\n",
    "\n",
    "The goal of this methods is common.\n",
    "For a given AR(1) model, we want to construct a discrete Markov chain process such that it matches the moments of the original AR(1) specification.\n",
    "This allows us to consider a sequence of discrete random variables in place of a sequence of continuous random variables.\n",
    "We want to do so because we numerically discretize the state variables of the Bellman equations, including stochastic ones.\n",
    "\n",
    "Before we move on, note that the process for $a$, conditional on the AR(1) specification, is entirely characterized by $\\mu$, $\\rho$ and $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tauchen (1986)\n",
    "\n",
    "This method is a classic.\n",
    "It is easy to code and easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tauchen(n, m, mu, rho, sigma):\n",
    "    sMax = m * sigma\n",
    "    S, step = np.linspace(-sMax, sMax, num=n, retstep=True)\n",
    "    x = S - rho * S.reshape((-1, 1)) + step/2\n",
    "    Pi = st.norm.cdf(x / sigma)\n",
    "    Pi[:, -1] = 1.\n",
    "    Pi[:, 1:] = np.diff(Pi)\n",
    "    S += mu  # centering around unconditional mean\n",
    "    return S, Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few comments on this code.\n",
    "We conveniently defined a function to implement the method.\n",
    "We need to know the following:\n",
    "- `n` the number of grid points we want to have;\n",
    "- `m` how far apart from the unconditional mean we want to go;\n",
    "- `mu`, the unconditional mean of the AR(1) process ($\\mu$);\n",
    "- `rho`, the persistence of the AR(1) process ($\\rho$); and\n",
    "- `sigma`, the standard deviation of the innovations.\n",
    "\n",
    "We start the procedure by assuming that the process has zero mean.\n",
    "We cherry-pick a value `sMax` that will be the maximum value on the grid.\n",
    "Given that the grid is centered around zero (for now), `-sMax` will be the minimum value.\n",
    "\n",
    "We then create the grid for the values of the random variable `S`, and we make sure we know the distance between one point and the next one, `step`.\n",
    "\n",
    "The matrix `x` is the ancestor of the transition matrix `Pi`, and it consists of the support of the normal random variable that governs transitions in the AR(1) specification.\n",
    "Because we are computing transition probabilities, the matrix `x` represents all possible transitions.\n",
    "\n",
    "`Pi` is defined by computing the Gaussian CDF at the gridpoints `x`, normalized by the dispersion `sigma`.\n",
    "Its last column is filled with ones and then we take first differences across columns (by default, [`np.diff`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.diff.html) operates along the last dimension--axis--of an array).\n",
    "This effectively implements what you have on the slides distributed by Marco.\n",
    "\n",
    "Finally, we re-center the grid `S` around the unconditional average of the process `mu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tauchen and Hussey (1991)\n",
    "\n",
    "This is an improvement upon Tauchen (1986).\n",
    "What it does is essentially the same as Tauchen, except that it leverages nodes in a Gauss-Hermite polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tauchussey(n, mu, rho, sigma):\n",
    "    S, step = np.polynomial.hermite.hermgauss(n)\n",
    "    S += np.sqrt(2) * sigma\n",
    "    pdf = ( st.norm.pdf(S, rho * S.reshape((-1,1)), sigma) /\n",
    "            st.norm.pdf(S, 0, sigma) )\n",
    "    Pi = step / np.sqrt(np.pi) * pdf\n",
    "    Pi /= Pi.sum(axis=1, keepdims=True)\n",
    "    S += mu\n",
    "    return S, Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, relative to Tauchen (1986), here we do not specify the parameter `m`.\n",
    "This means that this method does not allow us any control over the grid we want to obtain.\n",
    "\n",
    "The rest is very similar to Tauchen's method.\n",
    "The steps are organized the exact same way and the intuition is the same.\n",
    "The improvement lies in using nodes of Gauss-Hermite polynomials (both in determining the grid and in computing probabilities).\n",
    "This is a bit more sophisticated than using linearly spaced points for the grid and allows for a better match of the AR(1) moments we're targeting.\n",
    "\n",
    "To see how Gauss-Hermite nodes stack against linearly spaced points, take a look at [this dedicated notebook](../code_examples/hermgauss_vs_linspace.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rouwenhorst (see Kopecky and Suen, 2010)\n",
    "\n",
    "The Rouwenhorst method was already known, but was not very popular.\n",
    "Kopecky and Suen (2010) bring back the method to the attention of economists.\n",
    "\n",
    "The way it works is different than the other methods above.\n",
    "Here is the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouwenhorst(n, mu, rho, sigma):\n",
    "    def compute_P(p, n):\n",
    "        if n == 2:\n",
    "            P = np.array([[p, 1-p], [1-p, p]], dtype=float)\n",
    "        else:\n",
    "            Q = compute_P(p, n-1)\n",
    "            A = np.zeros((n, n))\n",
    "            B = np.zeros((n, n))\n",
    "            A[:n-1, :n-1] += Q\n",
    "            A[1:n, 1:n] += Q\n",
    "            B[:n-1, 1:n] += Q\n",
    "            B[1:n, :n-1] += Q\n",
    "            P = p * A + (1-p) * B\n",
    "            P[1:-1, :] /= 2\n",
    "        return P\n",
    "    p = (1 + rho) / 2\n",
    "    Pi = compute_P(p, n)\n",
    "    f = np.sqrt(n-1) * (sigma / np.sqrt(1 - rho**2))\n",
    "    S = np.linspace(-f, f, n) + mu\n",
    "    return S, Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way this works is easily visualized in Marco's slides.\n",
    "In a nutshell, the method starts by a 2-by-2 symmetric transition matrix.\n",
    "Symmetry here implies homoskedasticity of the error terms of the \"upstream\" AR(1) process.\n",
    "It then scales up the transition matrix to a `n`-by-`n` one by compounding successive iterations of the 2-by-2 case, carefully allocating values across the matrices `A` and `B`.\n",
    "\n",
    "Note that, similarly to the Tauchen and Hussey (1991) algorithm, the end user (us) have no manual control over the grid.\n",
    "This ensures that the grid points are properly chosen according to the (unconditional) support of the AR(1) process.\n",
    "\n",
    "Rouwenhorst's method is significantly more robust to highly persistent AR(1) processes relative to the methods above.\n",
    "This means that we can use this method is suitable for $|\\rho| > 0.9$ (this is just an eye-balled value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergodic distribution of a discrete Markov chain\n",
    "\n",
    "For nice Markov chains, it is useful to define the ergodic distribution of the states.\n",
    "This gives the long-run distribution of the exogenous variable we are trying to model.\n",
    "In case of stationary processes, this coincides with the unconditional probability distribution of the states.\n",
    "\n",
    "One way to compute ergodic distribution is to observe the following.\n",
    "Given a (right-stochastic) transition matrix $\\Pi$, the ergodic distribution $\\pi$ is characterized as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\begin{cases}\n",
    "        \\Pi' \\pi = \\pi \\\\\n",
    "        \\pi \\cdot \\iota = 1,\n",
    "    \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "where $\\iota$ is a vector of ones that is conformable to $\\pi$ for the inner product.\n",
    "\n",
    "This looks like an eigenvalue-eigenvector problem.\n",
    "The ergodic distribution $\\pi$ is the eigenvector of $\\Pi$ associated with the unit eigenvalue.\n",
    "However, eigenvectors and eigenvalues are unique only up to scale.\n",
    "This gives a role to the second equation in the system above, which gives us a way to choose the right scale we need.\n",
    "\n",
    "Hence, this routine follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ergodic_distribution(Pi):\n",
    "    l, v = la.eig(Pi)\n",
    "    vector = v[:, np.where(np.isclose(l, 1.))]\n",
    "    return (vector / np.sum(vector)).reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VFI and solution to the stochastic neo-classical growth model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have these methods, we can solve the problem above.\n",
    "This is not much different from the model in the previous TA session.\n",
    "All we do is adding a new state variable, which represents capital's productivity.\n",
    "\n",
    "Similarly to last time, we proceed in the following way:\n",
    "1. We calibrate the model;\n",
    "1. We create discrete grids for the state variables;\n",
    "1. We set a criterion for assessing convergence of the algorithm;\n",
    "1. We use VFI to solve the model; and\n",
    "1. We check the results graphically.\n",
    "\n",
    "We calibrate the model with the same parameters as the deterministic version of the model.\n",
    "However, we need to add values to characterize the exogenous process we introduced here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3\n",
    "beta = 0.95\n",
    "delta = 0.1\n",
    "gamma = 1.5\n",
    "u = lambda c : c**(1-gamma) / (1-gamma)\n",
    "\n",
    "mu = 0\n",
    "rho = 0.8\n",
    "sigma = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the discrete grids for the state variables.\n",
    "The grid for capital is obtained in the same way as last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nk = 1000\n",
    "\n",
    "k_dss = ((1 - (1-delta) * beta) / (alpha * beta)) ** (1 / (alpha-1))\n",
    "k_lo, k_hi = np.array([0.1, 2.5]) * k_dss\n",
    "\n",
    "K = np.linspace(k_lo, k_hi, num=Nk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid for capital productivity will be given by the procedure we use to discretize the AR(1) process.\n",
    "As we chose a relatively persistent process for productivity shocks, we are going to use Rouwenhorst's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Na = 2\n",
    "\n",
    "A, P = rouwenhorst(Na, mu, rho, sigma)\n",
    "A = np.exp(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Low productivity: exp(a) = 0.846\n",
      "   High productivity: exp(a) = 1.181\n",
      "Average productivity: exp(a) = 1.005\n"
     ]
    }
   ],
   "source": [
    "print('    Low productivity: exp(a) = {:.3f}\\n'.format(A[0]) + \n",
    "      '   High productivity: exp(a) = {:.3f}\\n'.format(A[-1]) +\n",
    "      'Average productivity: exp(a) = {:.3f}'.format(np.exp(mu + sigma**2/2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the average productivity is not unity.\n",
    "Because productivity is [log-normal](https://en.wikipedia.org/wiki/Log-normal_distribution), the average is $\\exp(\\mu + \\sigma^2/2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to preallocating the arrays that will store the results, setting the criterion to assess convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.zeros((Nk, Na))\n",
    "V0 = np.zeros((Nk, Na))\n",
    "V1 = np.zeros((Nk, Na))\n",
    "DRk = np.zeros((Nk, Na), dtype=int)\n",
    "\n",
    "criterion = 1.\n",
    "tolerance = 1e-6\n",
    "n_iter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally run VFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "while criterion > tolerance:\n",
    "    n_iter += 1\n",
    "    for i in range(Nk):\n",
    "        for j in range(Na):\n",
    "            C = A[j] * K[i]**alpha + (1 - delta) * K[i] - K\n",
    "            C[C < 0] = np.nan\n",
    "            U[:, j] = u(C)\n",
    "        objective = U + beta * V0 @ P.T\n",
    "        V1[i, :] = np.nanmax(objective, axis=0)\n",
    "        DRk[i, :] = np.nanargmax(objective, axis=0)\n",
    "    criterion = np.max(np.max(np.abs(V1 - V0)))\n",
    "    V0[:] = V1\n",
    "    \n",
    "t1 = time()\n",
    "\n",
    "K1 = K[DRk]\n",
    "C = np.zeros((Nk, Na))\n",
    "for j in range(Na):\n",
    "    C[:, j] = A[j] * K**alpha + (1 - delta) * K - K1[:, j]\n",
    "\n",
    "k_ss = K1[np.where(np.isclose(K.reshape((-1, 1)), K1))][np.array([2, -3])]\n",
    "\n",
    "print('Algorithm took {:.3f} seconds with {} iterations'.format((t1-t0),\n",
    "                                                                n_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes on what is going on here.\n",
    "\n",
    "First, note that the value `k_dss` that we computed above is the _deterministic_ steady state of capital.\n",
    "This means that `k_dss` is the steady state if all exogenous variables were deterministically set to their unconditional averages.\n",
    "Here, `k_ss` is the _vector_ of steady state capital holdings _conditional_ on productivity.\n",
    "In practice, this is computed by looking up where `K` and `K1` are closest to each other, with the small catch that no values of `K1` are identical to `K`.\n",
    "\n",
    "Second, we have two `for` loops in VFI.\n",
    "This happens because we need to construct counterfactual proposals for $V(k,a)$ for every value the state space might be.\n",
    "More in general, we will nest as many `for` loops as state variables.\n",
    "There are ways to get around this (e.g., vectorizing matrices), but researchers always try to squeeze state variables as much as possible (e.g., the _cash-in-hand_ trick in the Hugget and Aiyagari models we will see in later TA sessions).\n",
    "\n",
    "Third, we could be using PFI or direct projection also here.\n",
    "PFI in particular is suitable here because it dramatically reduces the amount of time required to converge to a solution.\n",
    "Direct projection is feasible, but I do not show it here because we saw it is not much reliable.\n",
    "\n",
    "We now turn to plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorstate = ['firebrick', 'green']\n",
    "V_labels = [r'$V(k, a^l)$', r'$V(k, a^h)$']\n",
    "C_labels = [r'$c(k, a^l)$', r'$c(k, a^h)$']\n",
    "K_labels = [r\"$k'(k, a^l)$\", r\"$k'(k, a^h)$\"]\n",
    "\n",
    "fig = plt.subplots(figsize=(12, 6))\n",
    "ax = [None] * 3\n",
    "\n",
    "pltgrid = (2, 2)\n",
    "ax[0] = plt.subplot2grid(pltgrid, (0, 0), rowspan=2)\n",
    "ax[1] = plt.subplot2grid(pltgrid, (0, 1))\n",
    "ax[2] = plt.subplot2grid(pltgrid, (1, 1))\n",
    "\n",
    "for a in range(Na):\n",
    "    ax[0].plot(K, V1[:, a],\n",
    "               linewidth=2,\n",
    "               color=colorstate[a],\n",
    "               label=V_labels[a])\n",
    "    ax[1].plot(K, K1[:, a],\n",
    "               linewidth=2,\n",
    "               color=colorstate[a],\n",
    "               label=K_labels[a],\n",
    "               zorder=2)\n",
    "    ax[2].plot(K, C[:, a],\n",
    "               linewidth=2,\n",
    "               color=colorstate[a],\n",
    "               label=C_labels[a])\n",
    "ax[1].plot(K, K,\n",
    "           linewidth=1,\n",
    "           color='black',\n",
    "           linestyle='dashed',\n",
    "           zorder=1)\n",
    "\n",
    "ax[0].set_title('Value function')\n",
    "ax[1].set_title('Capital accumulation decision')\n",
    "ax[2].set_title('Consumption decision')\n",
    "\n",
    "for a in range(3):\n",
    "    ax[a].axvline(k_ss[0],\n",
    "                  color=colorstate[0],\n",
    "                  linestyle='dotted',\n",
    "                  zorder=1)\n",
    "    ax[a].axvline(k_ss[1],\n",
    "                  color=colorstate[1],\n",
    "                  linestyle='dotted',\n",
    "                  zorder=1)\n",
    "    ax[a].grid(alpha=0.3)\n",
    "    ax[a].set_xlabel('$k$')\n",
    "    ax[a].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we plotted the value function $V(k,a)$ _conditional_ on $a$ assuming the value $a^l$ or $a^h$.\n",
    "We also observe that the conditional capital accumulation rules intersect the 45Â° line at two different values, which are the conditional steady states.\n",
    "The deterministic steady state lies in between, as it assumes that the exogenous variable always equals its unconditional average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('          Low steady state: k = {:.3f}\\n'.format(k_ss[0]) +\n",
    "      '         High steady state: k = {:.3f}\\n'.format(k_ss[1]) + \n",
    "      'Deterministic steady state: k = {:.3f}'.format(k_dss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the model\n",
    "\n",
    "By now we should be asking the question: why are we doing this?\n",
    "The main reason we numerically solve models is because we want to use analytically intractable equations to make predictions.\n",
    "Whether we have a normative or a positive model, we want to be able to verify certain properties of the (endogenous) variables in the model.\n",
    "\n",
    "So far, we obtained policy functions.\n",
    "These alone are not very informative.\n",
    "Moreover, as we typically reverse-engineer models to obtain certain results, we should have a pretty solid idea of what the policy functions look like.\n",
    "To further explore properties of the model, we need to simulate the model.\n",
    "This means repeatedly applying the solution of the model (which typically consists of policy functions + given laws of motion + given exogenous processes) to an initial condition.\n",
    "\n",
    "To gain further understanding, observe that a rational expectations model is described by the following system of equations:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{E}_t \\big( F(X_{t-1}, X_t, X_{t+1}) \\big) = 0,\n",
    "\\end{align*}\n",
    "\n",
    "where $X_t$ is the vector of all endogenous and exogenous variables of the model, and the associated solution looks like\n",
    "\n",
    "\\begin{align*}\n",
    "    X_{t+1} = G(X_{t-1}, X_t).\n",
    "\\end{align*}\n",
    "\n",
    "The (vector) function $G(\\cdot)$, together with an initial condition $X_0$, induces a sequence ${(X_t)}_{t=0}^{\\infty}$ that we call _simulation_.\n",
    "In a baseline DSGE model, as we have representative-agents economies, the simulation is the time series of the vector of variables of the model.\n",
    "These time series will feature typical moments, such as unconditional (historical) averages, conditional averages, cross-correlations and auto-correlations.\n",
    "We typically want to compare these moments against those we observe in the data to assess a model.\n",
    "\n",
    "In what follows, we simulate the model we solved above.\n",
    "What we have here is not a state-of-the-art exercise.\n",
    "In particular, we are dealing with a two-points grid for productivity, and hence we draw from these two values only (we can improve on this, keeping a two-points grid for $a$: how?).\n",
    "\n",
    "We proceed in the following way.\n",
    "For every period $t$:\n",
    "1. We enter period $t$ with given capital holdings $k_t$;\n",
    "1. We draw a realization of $a_t$;\n",
    "1. We use the policy function $c(k_t)$ to obtain $c_t$;\n",
    "1. We use the policy function $k'(k_t)$ to obtain $k_{t+1}$;\n",
    "1. We use definitions in the model to compute output $y_t$ and investment $i_t$; and\n",
    "1. We move on to period $t+1$ with the state $k_{t+1}$.\n",
    "\n",
    "The code does this heavily relying on indices: we are drawing `i in range(Na)` instead of `a in A`.\n",
    "We also use the policy functions by using indices.\n",
    "\n",
    "First, let us define useful functions for drawing integers from a known (discrete) distribution function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_state(pdf):\n",
    "    cdf = np.cumsum(pdf)\n",
    "    u = np.random.uniform()\n",
    "    state_index = np.sum(u - cdf > 0)\n",
    "    return int(state_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we define a function that considers the closest possible element to `value` in a given `array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value, give_idx=False):\n",
    "    if array.ndim != 1:\n",
    "        raise ValueError('Input vector must be uni-dimensional')\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    if give_idx:\n",
    "        return idx\n",
    "    else:\n",
    "        return array[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define how long we want our simulation to be, and we preallocate the arrays where we store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 250\n",
    "\n",
    "a = np.zeros((T,), dtype=int)\n",
    "k = np.zeros((T,), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to choose initial conditions for the simulations.\n",
    "This is completely arbitrary a choice.\n",
    "Given that the policy function $G(\\cdot)$ naturally defines autocorrelated endogenous variables, the choice of the initial condition is non-trivial.\n",
    "In particular, every realization we draw from the model will depend on them, however marginally.\n",
    "\n",
    "There are two good candidates here.\n",
    "One way is to pick steady state values.\n",
    "This ensures that the initial condition does not look too farfetched relative to the rest of the simulation.\n",
    "The second way is to simulate the model for many more periods than `T` and to just consider the last `T` \"observations.\"\n",
    "This should intuitively remove any (numerical) correlation with the initial condition.\n",
    "\n",
    "Here, we pick the steady state values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0] = draw_state(ergodic_distribution(P))  # drawing an index for grid A\n",
    "k[0] = find_nearest(K, k_dss, give_idx=True)    # getting index for K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the stochastic NeoClassical Growth Model is \"small,\" we just need to simulate productivity and capital holdings at every iteration of the `for` loop that follows.\n",
    "The other endogenous variables we look at here (i.e., consumption, production and investment) are all deterministic functions of $(k_t, a_t)$.\n",
    "This is because $k_t$ and $a_t$ are the state variables of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(T-1):\n",
    "    a[t+1] = draw_state(P[a[t], :])  # drawing an index for grid A\n",
    "    k[t+1] = DRk[k[t], a[t]]         # drawing an index for grid K\n",
    "\n",
    "capital = K[k]\n",
    "shocks = A[a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are left with computing the other interesting variables of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production = np.zeros((T,))\n",
    "investment = np.zeros((T,))\n",
    "consumption = np.zeros((T,))\n",
    "\n",
    "for t in range(T-1):\n",
    "    production[t] = shocks[t] * capital[t] ** alpha\n",
    "    investment[t] = capital[t+1] - (1 - delta) * capital[t]\n",
    "    consumption[t] = production[t] - investment[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we did not compute certain values.\n",
    "Particularly, investment in the last period, $i_T$, has not been computed because it relies on the value $k_{T+1}$, which we did not simulate above.\n",
    "Similarly, we cannot have consumption in the last period, $c_T$.\n",
    "For these two reasons, we prematurely stopped the iteration of the simulation (i.e., the last value in `range(T-1)` is `T-2`, which is the second to last admissible position in an array with `T` elements).\n",
    "Consequently, we did not compute production in the last period, $y_T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production[-1] = shocks[-1] * capital[-1] ** alpha\n",
    "investment[-1] = np.nan\n",
    "consumption[-1] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every of these variables, we can compute the corresponding _conditional_ steady states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ss = A * k_ss ** alpha\n",
    "i_ss = delta * k_ss  # k_ss - (1 - delta) * k_ss\n",
    "c_ss = y_ss - i_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to plot the simulations.\n",
    "We do so by shading low-productivity times in gray, in a similar ways to what [FRED does in their figures with NBER recessions](https://fred.stlouisfed.org/series/GDPC1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lows = shocks < 1\n",
    "low_in = [i for i in range(1, T) if (lows[i-1] == False and lows[i] == True)]\n",
    "low_out = [i for i in range(T-1) if (lows[i] == True and lows[i+1] == False)]\n",
    "if lows[0] == True:\n",
    "    low_in.insert(0, 0)\n",
    "if lows[T-1] == True:\n",
    "    low_out.append(T-1)\n",
    "\n",
    "prop_sims = {'color':     'blue',\n",
    "             'linewidth': 1.5,\n",
    "             'zorder':    3,\n",
    "             'label':     'Sample path'}\n",
    "\n",
    "prop_ss_lo = {'color':     colorstate[0],\n",
    "              'linewidth': 1,\n",
    "              'linestyle': 'dashed',\n",
    "              'zorder':    2,\n",
    "              'label':     'Low steady state'}\n",
    "\n",
    "prop_ss_hi = {'color':     colorstate[1],\n",
    "              'linewidth': 1,\n",
    "              'linestyle': 'dashed',\n",
    "              'zorder':    2,\n",
    "              'label':     'High steady state'}\n",
    "\n",
    "fig1, ax1 = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True,\n",
    "                         figsize=(12, 6))\n",
    "\n",
    "ax1[0, 0].plot(consumption, **prop_sims)\n",
    "ax1[0, 1].plot(investment,  **prop_sims)\n",
    "ax1[1, 0].plot(capital,     **prop_sims)\n",
    "ax1[1, 1].plot(production,  **prop_sims)\n",
    "\n",
    "ax1[0, 0].axhline(c_ss[0], **prop_ss_lo)\n",
    "ax1[0, 0].axhline(c_ss[1], **prop_ss_hi)\n",
    "ax1[0, 1].axhline(i_ss[0], **prop_ss_lo)\n",
    "ax1[0, 1].axhline(i_ss[1], **prop_ss_hi)\n",
    "ax1[1, 0].axhline(k_ss[0], **prop_ss_lo)\n",
    "ax1[1, 0].axhline(k_ss[1], **prop_ss_hi)\n",
    "ax1[1, 1].axhline(y_ss[0], **prop_ss_lo)\n",
    "ax1[1, 1].axhline(y_ss[1], **prop_ss_hi)\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax1[i, j].set_xlabel('Time')\n",
    "        ax1[i, j].grid(alpha=0.3)\n",
    "        ax1[i, j].legend(framealpha=1)\n",
    "        for a, b in zip(low_in, low_out):\n",
    "            ax1[i, j].axvspan(a, b, color='black', alpha=0.1, zorder=1)\n",
    "\n",
    "ax1[0, 0].set_title('Consumption')\n",
    "ax1[0, 1].set_title('Investment')\n",
    "ax1[1, 0].set_title('Capital')\n",
    "ax1[1, 1].set_title('Production')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few remarks are due.\n",
    "\n",
    "As soon as a \"good\" period starts (i.e., the beginning of each non-shaded area), the agent realizes to be in a high productivity regime.\n",
    "This makes her react consistently with the policy functions $c(k, a^h)$ and $k'(k, a^h)$.\n",
    "If a given regime lasts long enough, every variable converges to the respective conditional steady state.\n",
    "The only way to deviate from such convergence is to receive a regime-switching shock.\n",
    "\n",
    "Although the policy functions incorporate averaged future payoffs (i.e., are obtained by optimizing $\\mathbf{E} \\left( V \\left( k',a' \\right) \\right)$), the simulations never converge to average values.\n",
    "If we had multiple productivity values, we would have multiple levels at which the simulations may converge.\n",
    "\n",
    "Moreover, these simulations are not very realistic.\n",
    "We draw only two possible values of productivity in order to stay on the grid on which we solved the model.\n",
    "By increasing the number of values in the grid for the state space, we can obtain more compelling paths for the endogenous variables.\n",
    "\n",
    "Finally, given the sample realizations for `consumption`, `investment`, `capital` and `production`, we can compute numerical statistics to compare against real-world moments.\n",
    "For example, we can compute historical averages, historical volatilities, cross-correlations and auto-correlations.\n",
    "This exercise, however, critically depends on the calibration of the model, especially when it comes to the unit of measurements and the frequency at which the model is simulated.\n",
    "In this particular case, having output roughly between 1 and 2 is not particularly meaningful.\n",
    "However, we can interpret the other variables _relative to_ output in terms of their magnitude."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
